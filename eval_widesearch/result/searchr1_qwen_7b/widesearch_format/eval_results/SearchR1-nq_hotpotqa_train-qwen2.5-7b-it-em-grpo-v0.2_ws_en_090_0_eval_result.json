{
    "instance_id": "ws_en_090",
    "score": 0.0,
    "precision_by_row": 0.0,
    "recall_by_row": 0.0,
    "f1_by_row": 0.0,
    "precision_by_item": 0.5714285714285714,
    "recall_by_item": 0.13445378151260504,
    "f1_by_item": 0.21768707482993196,
    "msg": "   modelname_exact_match  company_llm_judge  contextwindow_llm_judge  aime2025_number_near  swe-benchverified_number_near  tau-bench-airline_number_near  tau-bench-retail_number_near\n0                    1.0                  1                        1                   0.0                            0.0                            1.0                           1.0\n1                    1.0                  1                        1                   0.0                            0.0                            1.0                           1.0\n2                    1.0                  1                        1                   0.0                            1.0                            1.0                           1.0"
}