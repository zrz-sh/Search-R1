{
    "instance_id": "ws_en_051",
    "score": 0.0,
    "precision_by_row": 0.0,
    "recall_by_row": 0.0,
    "f1_by_row": 0.0,
    "precision_by_item": 0.04285714285714286,
    "recall_by_item": 0.008571428571428572,
    "f1_by_item": 0.014285714285714287,
    "msg": "   highschool_exact_match  states_llm_judge  stemhighschoolsranking_exact_match  nationalrankings_exact_match  staterankings_llm_judge  servedgrades_llm_judge  apcourses_number_near\n0                     1.0                 0                                 0.0                           0.0                        0                       0                    0.0\n1                     1.0                 1                                 0.0                           0.0                        0                       0                    0.0"
}