{
    "instance_id": "ws_en_051",
    "score": 0.0,
    "precision_by_row": 0.0,
    "recall_by_row": 0.0,
    "f1_by_row": 0.0,
    "precision_by_item": 0.06349206349206349,
    "recall_by_item": 0.011428571428571429,
    "f1_by_item": 0.019370460048426148,
    "msg": "   highschool_exact_match  states_llm_judge  stemhighschoolsranking_exact_match  nationalrankings_exact_match  staterankings_llm_judge  servedgrades_llm_judge  apcourses_number_near\n0                     1.0                 0                                 0.0                           0.0                        0                       1                    0.0\n1                     1.0                 1                                 0.0                           0.0                        0                       0                    0.0"
}